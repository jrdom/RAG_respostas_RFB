{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Instalaçao de Bibliotecas\n",
        "\n",
        "!pip install pymupdf\n",
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install pypdf\n",
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEnuNZEWCLAA",
        "outputId": "a9375bbb-3a9c-4802-93fa-73230a484a16",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.24.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extração de Normas\n",
        "\n",
        "import pdfplumber\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def extrair_texto_pdf(pdf_path):\n",
        "    texto_completo = ''\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            texto_pagina = page.extract_text()\n",
        "            if texto_pagina:\n",
        "                texto_completo += texto_pagina + '\\n'\n",
        "    return texto_completo\n",
        "\n",
        "def extrair_normas_legais(texto):\n",
        "    # Padrões de normas legais mais comuns\n",
        "    padroes = [\n",
        "        # Padrões PGFN\n",
        "        r'Parecer\\s+SEI\\s+(?:Nº\\s+)?[\\d\\.]+/\\d{4}/(?:CRJ/PGACET/)?PGFN(?:-MF|-ME)?',\n",
        "        r'Nota\\s+SEI\\s+(?:nº\\s+)?[\\d\\.]+/\\d{4}/(?:CRJ/PGACET/)?PGFN(?:-MF|-ME)?',\n",
        "        r'Parecer\\s+PGFN/(?:CAT|PGA|CRJ)/(?:Nº\\s+)?[\\d\\.]+(?:/\\d{4})?',\n",
        "        r'Nota\\s+PGFN\\s+(?:CRJ\\s+)?(?:nº\\s+)?[\\d\\.]+/\\d{4}',\n",
        "        r'(?:Ato\\s+Declaratório\\s+)?PGFN(?:/CRJ)?(?:/Nº\\s+)?[\\d\\.]+(?:/\\d{4})?',\n",
        "        r'AD\\s+PGFN\\s+(?:nº\\s+)?[\\d\\.]+',\n",
        "        r'Ato\\s+Declaratório\\s+PGFN\\s+(?:nº\\s+)?[\\d\\.]+',\n",
        "\n",
        "        # Instrução Normativa\n",
        "        r'Instrução\\s+Normativa\\s+(?:RFB\\s+)?(?:SRF\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Lei\n",
        "        r'Lei\\s+(?:Complementar\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Decreto\n",
        "        r'Decreto\\s+n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Ato Declaratório RFB\n",
        "        r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:RFB\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Ato Declaratório SRF\n",
        "        r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:SRF\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Ato Declaratório CST\n",
        "        r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:CST\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Ato Declaratório COSIT\n",
        "        r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:Cosit\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Ato Declaratório COSAR\n",
        "        r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:Cosar\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Portaria\n",
        "        r'Portaria\\s+(?:RFB\\s+)?(?:MF\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Resolução\n",
        "        r'Resolução\\s+(?:RFB\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Medida Provisória\n",
        "        r'Medida\\s+Provisória\\s+n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Parecer Normativo\n",
        "        r'Parecer\\s+Normativo\\s+(?:RFB\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # Solução de Consulta\n",
        "        r'Solução\\s+de\\s+Consulta\\s+(?:Cosit\\s+)?n[º°]\\s*[\\d\\.]+(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "        # RIR\n",
        "        r'RIR/\\d{4}'\n",
        "    ]\n",
        "\n",
        "    # Combinar todos os padrões em uma única expressão regular\n",
        "    padrao_combinado = '|'.join(f'({padrao})' for padrao in padroes)\n",
        "\n",
        "    # Encontrar todas as normas no texto\n",
        "    normas = re.finditer(padrao_combinado, texto, re.IGNORECASE)\n",
        "\n",
        "    # Processar e limpar as normas encontradas\n",
        "    normas_encontradas = []\n",
        "    for norma in normas:\n",
        "        norma_texto = norma.group(0).strip()\n",
        "        # Remover artigos e incisos\n",
        "        norma_texto = re.sub(r',\\s*art\\.[^,]*', '', norma_texto, flags=re.IGNORECASE)\n",
        "        norma_texto = re.sub(r',\\s*inciso[^,]*', '', norma_texto, flags=re.IGNORECASE)\n",
        "        if norma_texto and norma_texto not in normas_encontradas:\n",
        "            normas_encontradas.append(norma_texto)\n",
        "\n",
        "    return normas_encontradas\n",
        "\n",
        "def extrair_normas(pdf_path):\n",
        "    # Extrair texto do PDF\n",
        "    texto_completo = extrair_texto_pdf(pdf_path)\n",
        "    texto_completo = re.sub(r'\\s+', ' ', texto_completo).strip()\n",
        "\n",
        "    # Regex para identificar perguntas\n",
        "    regex_pergunta = re.compile(r'(\\d{1,3})\\s*—\\s*(.+?\\?)')\n",
        "    matches = list(regex_pergunta.finditer(texto_completo))\n",
        "\n",
        "    # Coletar perguntas e normas\n",
        "    normas_extracao = []\n",
        "\n",
        "    for idx, match in enumerate(matches):\n",
        "        numero_pergunta = match.group(1)\n",
        "        texto_pergunta = match.group(2).strip()\n",
        "\n",
        "        # Pegar texto de resposta\n",
        "        end_pos = match.end()\n",
        "        if idx + 1 < len(matches):\n",
        "            start_next = matches[idx + 1].start()\n",
        "            texto_resposta = texto_completo[end_pos:start_next].strip()\n",
        "        else:\n",
        "            texto_resposta = texto_completo[end_pos:].strip()\n",
        "\n",
        "        # Extrair normas da resposta\n",
        "        normas_encontradas = extrair_normas_legais(texto_resposta)\n",
        "\n",
        "        normas_extracao.append({\n",
        "            \"Pergunta\": f\"{numero_pergunta} — {texto_pergunta}\",\n",
        "            \"Norma\": \"; \".join(normas_encontradas) if normas_encontradas else \"não tem norma legal para essa pergunta\"\n",
        "        })\n",
        "\n",
        "    return normas_extracao\n",
        "\n",
        "# Uso do código\n",
        "pdf_path = \"/content/P&R IRPF 2024 - v1.0 - 2024.05.03 (2).pdf\"\n",
        "\n",
        "# Extrair normas e converter para DataFrame\n",
        "normas_extracao = extrair_normas(pdf_path)\n",
        "df_normas = pd.DataFrame(normas_extracao)\n",
        "\n",
        "# Exibir e salvar em Excel\n",
        "print(df_normas.head(10))\n",
        "df_normas.to_excel('normas_extraidas.xlsx', index=False)\n",
        "\n",
        "# Baixar o arquivo no Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('normas_extraidas.xlsx')\n",
        "except:\n",
        "    print(\"Arquivo salvo localmente como 'normas_extraidas.xlsx'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "Ug_42uyMdodC",
        "outputId": "e9d98443-4a40-4280-e033-b3968628f4b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Pergunta  \\\n",
            "0  001 — Quem está obrigado a apresentar a Declar...   \n",
            "1  002 — Pessoa física desobrigada pode apresenta...   \n",
            "2  003 — Contribuinte que é titular ou sócio de e...   \n",
            "3  004 — Contribuinte, que participou de quadro s...   \n",
            "4  005 — Contribuinte que constou como responsáve...   \n",
            "5  006 — Existe limite de idade para a obrigatori...   \n",
            "6  007 — Para verificação da obrigatoriedade de a...   \n",
            "7  008 — A posse ou a propriedade de bens e direi...   \n",
            "8  009 — O contribuinte deve apresentar uma Decla...   \n",
            "9  010 — Dependente que possui depósito em conta ...   \n",
            "\n",
            "                                               Norma  \n",
            "0  Lei nº 11.196, de 21 de novembro de 2005; Lei ...  \n",
            "1  Instrução Normativa RFB nº 2.178, de 5 de març...  \n",
            "2  Instrução Normativa RFB nº 2.178, de 5 de març...  \n",
            "3  Instrução Normativa RFB nº 2.178, de 5 de març...  \n",
            "4  Instrução Normativa RFB nº 2.178, de 5 de març...  \n",
            "5  RIR/2018; Decreto nº 9.580, de 22 de novembro ...  \n",
            "6  Lei nº 9.250, de 26 de dezembro de 1995; Instr...  \n",
            "7  Instrução Normativa RFB nº 2.178, de 5 de març...  \n",
            "8  Instrução Normativa RFB nº 2.178, de 5 de març...  \n",
            "9  Instrução Normativa RFB nº 2.178, de 5 de març...  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6650869a-becd-4634-b5b0-de4ee303967f\", \"normas_extraidas.xlsx\", 49508)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Elminação de Duplicatas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def limpar_norma(norma):\n",
        "    \"\"\"Função auxiliar para limpar cada norma individual\"\"\"\n",
        "    return norma.strip().replace('\\n', ' ').replace('  ', ' ')\n",
        "\n",
        "def analisar_normas_excel(caminho_arquivo):\n",
        "    # Ler o arquivo Excel\n",
        "    print(\"Lendo arquivo Excel...\")\n",
        "    df = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "    # Criar lista de todas as normas\n",
        "    todas_normas = []\n",
        "    print(\"\\nProcessando normas...\")\n",
        "\n",
        "    for idx, normas_string in enumerate(df['Norma'], 1):\n",
        "        # Pular entradas sem normas\n",
        "        if isinstance(normas_string, str):  # Verificar se é string\n",
        "            if normas_string == \"não tem norma legal para essa pergunta\":\n",
        "                continue\n",
        "\n",
        "            # Dividir múltiplas normas da mesma célula\n",
        "            normas_lista = normas_string.split(';')\n",
        "\n",
        "            # Limpar cada norma individualmente\n",
        "            for norma in normas_lista:\n",
        "                norma_limpa = limpar_norma(norma)\n",
        "                if norma_limpa:  # Adicionar apenas se não estiver vazia\n",
        "                    todas_normas.append(norma_limpa)\n",
        "\n",
        "    # Criar conjunto para remover duplicatas e depois converter para lista ordenada\n",
        "    normas_unicas = sorted(set(todas_normas))\n",
        "\n",
        "    # Criar DataFrame com normas únicas\n",
        "    df_normas_unicas = pd.DataFrame(normas_unicas, columns=['Norma'])\n",
        "\n",
        "    # Adicionar coluna com numeração\n",
        "    df_normas_unicas.insert(0, 'ID', range(1, len(df_normas_unicas) + 1))\n",
        "\n",
        "    # Imprimir estatísticas detalhadas\n",
        "    print(\"\\nEstatísticas:\")\n",
        "    print(f\"Total de normas encontradas (com repetições): {len(todas_normas)}\")\n",
        "    print(f\"Total de normas únicas: {len(normas_unicas)}\")\n",
        "\n",
        "    # Calcular e mostrar as normas mais frequentes\n",
        "    normas_freq = pd.Series(todas_normas).value_counts()\n",
        "    print(\"\\nTop 10 normas mais frequentes:\")\n",
        "    for norma, freq in normas_freq.head(10).items():\n",
        "        print(f\"{freq} ocorrências: {norma}\")\n",
        "\n",
        "    # Salvar normas únicas em um novo arquivo Excel\n",
        "    nome_arquivo_saida = 'normas_unicas.xlsx'\n",
        "    df_normas_unicas.to_excel(nome_arquivo_saida, index=False)\n",
        "\n",
        "    # Salvar arquivo com frequência das normas\n",
        "    nome_arquivo_freq = 'frequencia_normas.xlsx'\n",
        "    df_frequencia = pd.DataFrame({\n",
        "        'Norma': normas_freq.index,\n",
        "        'Frequência': normas_freq.values\n",
        "    })\n",
        "    df_frequencia.to_excel(nome_arquivo_freq, index=False)\n",
        "\n",
        "    # Se estiver no Google Colab, fazer o download dos arquivos\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(nome_arquivo_saida)\n",
        "        files.download(nome_arquivo_freq)\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados e estão disponíveis para download.\")\n",
        "    except:\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados no diretório atual.\")\n",
        "\n",
        "    # Mostrar as primeiras normas únicas encontradas\n",
        "    print(\"\\nPrimeiras 10 normas únicas encontradas:\")\n",
        "    print(df_normas_unicas.head(10))\n",
        "\n",
        "    return df_normas_unicas, df_frequencia\n",
        "\n",
        "# Usar a função\n",
        "try:\n",
        "    caminho_arquivo = 'normas_extraidas.xlsx'  # Arquivo gerado pelo código anterior\n",
        "    df_normas, df_freq = analisar_normas_excel(caminho_arquivo)\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao processar o arquivo: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "cnnjn-IV7m6V",
        "outputId": "7e29d4c6-5341-480e-b21e-824f65980801"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo arquivo Excel...\n",
            "\n",
            "Processando normas...\n",
            "\n",
            "Estatísticas:\n",
            "Total de normas encontradas (com repetições): 1839\n",
            "Total de normas únicas: 396\n",
            "\n",
            "Top 10 normas mais frequentes:\n",
            "260 ocorrências: RIR/2018\n",
            "257 ocorrências: Decreto nº 9.580, de 22 de novembro de 2018\n",
            "122 ocorrências: Instrução Normativa RFB nº 1.500, de 29 de outubro de 2014\n",
            "74 ocorrências: Lei nº 9.250, de 26 de dezembro de 1995\n",
            "69 ocorrências: Lei nº 7.713, de 22 de dezembro de 1988\n",
            "66 ocorrências: Instrução Normativa SRF nº 83, de 11 de outubro de 2001\n",
            "53 ocorrências: Instrução Normativa SRF nº 208, de 27 de setembro de 2002\n",
            "48 ocorrências: Instrução Normativa RFB nº 2.178, de 5 de março de 2024\n",
            "45 ocorrências: Instrução Normativa SRF nº 84, de 11 de outubro de 2001\n",
            "37 ocorrências: Instrução Normativa RFB nº 1.585, de 31 de agosto de 2015\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6d5fcd3a-905d-428f-aa27-4fbd9d0fef34\", \"normas_unicas.xlsx\", 13134)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b7ee097d-64f7-4614-8da1-f0a56ce57f36\", \"frequencia_normas.xlsx\", 12429)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Arquivos 'normas_unicas.xlsx' e 'frequencia_normas.xlsx' foram gerados e estão disponíveis para download.\n",
            "\n",
            "Primeiras 10 normas únicas encontradas:\n",
            "   ID                                              Norma\n",
            "0   1                                       AD PGFN nº 3\n",
            "1   2  Ato Declaratório Cosar nº 47, de 27 de novembr...\n",
            "2   3  Ato Declaratório Interpretativo RFB nº 1, de 1...\n",
            "3   4  Ato Declaratório Interpretativo RFB nº 18, de ...\n",
            "4   5  Ato Declaratório Interpretativo RFB nº 3, de 2...\n",
            "5   6          Ato Declaratório Interpretativo SRF nº 14\n",
            "6   7  Ato Declaratório Interpretativo SRF nº 14, de ...\n",
            "7   8  Ato Declaratório Interpretativo SRF nº 16, de ...\n",
            "8   9  Ato Declaratório Interpretativo SRF nº 2, de 2...\n",
            "9  10  Ato Declaratório Interpretativo SRF nº 24, de ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''#@title Normalização\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def padronizar_norma(norma):\n",
        "    \"\"\"Função para padronizar o formato da norma removendo datas e outros elementos variáveis\"\"\"\n",
        "    if not isinstance(norma, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Limpar espaços e quebras de linha\n",
        "    norma = norma.strip().replace('\\n', ' ').replace('  ', ' ')\n",
        "\n",
        "    # Padrões de normalização\n",
        "    padroes_normalizacao = [\n",
        "        # Lei (com ou sem data)\n",
        "        (r'Lei\\s+(?:Complementar\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Lei nº {m.group(1)}'),\n",
        "\n",
        "        # Instrução Normativa\n",
        "        (r'Instrução\\s+Normativa\\s+(?:RFB\\s+)?(?:SRF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Instrução Normativa RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Decreto\n",
        "        (r'Decreto\\s*n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Decreto nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório RFB\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Ato Declaratório RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório SRF\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:SRF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Ato Declaratório SRF nº {m.group(1)}'),\n",
        "\n",
        "        # Portaria\n",
        "        (r'Portaria\\s+(?:RFB\\s+)?(?:MF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Portaria RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Resolução\n",
        "        (r'Resolução\\s+(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Resolução RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Medida Provisória\n",
        "        (r'Medida\\s+Provisória\\s+n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Medida Provisória nº {m.group(1)}'),\n",
        "\n",
        "        # Parecer Normativo\n",
        "        (r'Parecer\\s+Normativo\\s+(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Parecer Normativo RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Solução de Consulta\n",
        "        (r'Solução\\s+de\\s+Consulta\\s+(?:Cosit\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Solução de Consulta Cosit nº {m.group(1)}'),\n",
        "\n",
        "        # RIR\n",
        "        (r'RIR/(\\d{4})',\n",
        "         lambda m: f'RIR/{m.group(1)}')\n",
        "    ]\n",
        "\n",
        "    # Aplicar cada padrão de normalização\n",
        "    norma_padronizada = norma\n",
        "    for padrao, substituicao in padroes_normalizacao:\n",
        "        match = re.search(padrao, norma, re.IGNORECASE)\n",
        "        if match:\n",
        "            norma_padronizada = substituicao(match)\n",
        "            break\n",
        "\n",
        "    return norma_padronizada\n",
        "\n",
        "def analisar_normas_excel(caminho_arquivo):\n",
        "    # Ler o arquivo Excel\n",
        "    print(\"Lendo arquivo Excel...\")\n",
        "    df = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "    # Criar lista de todas as normas\n",
        "    todas_normas = []\n",
        "    print(\"\\nProcessando e padronizando normas...\")\n",
        "\n",
        "    for normas_string in df['Norma']:\n",
        "        if isinstance(normas_string, str):\n",
        "            if normas_string == \"não tem norma legal para essa pergunta\":\n",
        "                continue\n",
        "\n",
        "            # Dividir múltiplas normas da mesma célula\n",
        "            normas_lista = normas_string.split(';')\n",
        "\n",
        "            # Padronizar cada norma individualmente\n",
        "            for norma in normas_lista:\n",
        "                norma_padronizada = padronizar_norma(norma)\n",
        "                if norma_padronizada:  # Adicionar apenas se não estiver vazia\n",
        "                    todas_normas.append(norma_padronizada)\n",
        "\n",
        "    # Criar conjunto para remover duplicatas e depois converter para lista ordenada\n",
        "    normas_unicas = sorted(set(todas_normas))\n",
        "\n",
        "    # Criar DataFrame com normas únicas\n",
        "    df_normas_unicas = pd.DataFrame(normas_unicas, columns=['Norma'])\n",
        "\n",
        "    # Adicionar coluna com numeração\n",
        "    df_normas_unicas.insert(0, 'ID', range(1, len(df_normas_unicas) + 1))\n",
        "\n",
        "    # Imprimir estatísticas detalhadas\n",
        "    print(\"\\nEstatísticas:\")\n",
        "    print(f\"Total de normas encontradas (com repetições): {len(todas_normas)}\")\n",
        "    print(f\"Total de normas únicas após padronização: {len(normas_unicas)}\")\n",
        "\n",
        "    # Calcular e mostrar as normas mais frequentes\n",
        "    normas_freq = pd.Series(todas_normas).value_counts()\n",
        "    print(\"\\nTop 10 normas mais frequentes:\")\n",
        "    for norma, freq in normas_freq.head(10).items():\n",
        "        print(f\"{freq} ocorrências: {norma}\")\n",
        "\n",
        "    # Salvar normas únicas em um novo arquivo Excel\n",
        "    nome_arquivo_saida = 'normas_unicas_padronizadas.xlsx'\n",
        "    df_normas_unicas.to_excel(nome_arquivo_saida, index=False)\n",
        "\n",
        "    # Salvar arquivo com frequência das normas\n",
        "    nome_arquivo_freq = 'frequencia_normas_padronizadas.xlsx'\n",
        "    df_frequencia = pd.DataFrame({\n",
        "        'Norma': normas_freq.index,\n",
        "        'Frequência': normas_freq.values\n",
        "    })\n",
        "    df_frequencia.to_excel(nome_arquivo_freq, index=False)\n",
        "\n",
        "    # Se estiver no Google Colab, fazer o download dos arquivos\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(nome_arquivo_saida)\n",
        "        files.download(nome_arquivo_freq)\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados e estão disponíveis para download.\")\n",
        "    except:\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados no diretório atual.\")\n",
        "\n",
        "    # Mostrar as primeiras normas únicas encontradas\n",
        "    print(\"\\nPrimeiras 10 normas únicas encontradas:\")\n",
        "    print(df_normas_unicas.head(10))\n",
        "\n",
        "    return df_normas_unicas, df_frequencia\n",
        "\n",
        "# Usar a função\n",
        "try:\n",
        "    caminho_arquivo = 'normas_extraidas.xlsx'  # Arquivo gerado pelo código anterior\n",
        "    df_normas, df_freq = analisar_normas_excel(caminho_arquivo)\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao processar o arquivo: {str(e)}\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "FLsR5wwdBOHC",
        "outputId": "36b996ef-0a48-472f-8306-917caab4cc16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo arquivo Excel...\n",
            "\n",
            "Processando e padronizando normas...\n",
            "\n",
            "Estatísticas:\n",
            "Total de normas encontradas (com repetições): 1790\n",
            "Total de normas únicas após padronização: 301\n",
            "\n",
            "Top 10 normas mais frequentes:\n",
            "260 ocorrências: RIR/2018\n",
            "260 ocorrências: Decreto nº 9.580\n",
            "123 ocorrências: Instrução Normativa RFB nº 1.500\n",
            "79 ocorrências: Lei nº 7.713\n",
            "77 ocorrências: Lei nº 9.250\n",
            "67 ocorrências: Instrução Normativa RFB nº 83\n",
            "56 ocorrências: Instrução Normativa RFB nº 208\n",
            "48 ocorrências: Instrução Normativa RFB nº 2.178\n",
            "47 ocorrências: Instrução Normativa RFB nº 84\n",
            "39 ocorrências: Instrução Normativa RFB nº 1.585\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ee0d27e1-01e5-4762-a4a2-9e31a903044c\", \"normas_unicas_padronizadas.xlsx\", 9961)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bbdccef7-4d90-40a6-8897-fb5c6cf98c9e\", \"frequencia_normas_padronizadas.xlsx\", 9269)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Arquivos 'normas_unicas_padronizadas.xlsx' e 'frequencia_normas_padronizadas.xlsx' foram gerados e estão disponíveis para download.\n",
            "\n",
            "Primeiras 10 normas únicas encontradas:\n",
            "   ID                       Norma\n",
            "0   1   Ato Declaratório RFB nº 1\n",
            "1   2  Ato Declaratório RFB nº 16\n",
            "2   3  Ato Declaratório RFB nº 18\n",
            "3   4   Ato Declaratório RFB nº 3\n",
            "4   5           Decreto nº 21.177\n",
            "5   6           Decreto nº 27.784\n",
            "6   7            Decreto nº 3.000\n",
            "7   8              Decreto nº 361\n",
            "8   9            Decreto nº 4.897\n",
            "9  10            Decreto nº 5.128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Normalização\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def padronizar_norma(norma):\n",
        "    \"\"\"Função para padronizar o formato da norma removendo datas e outros elementos variáveis\"\"\"\n",
        "    if not isinstance(norma, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Limpar espaços e quebras de linha\n",
        "    norma = norma.strip().replace('\\n', ' ').replace('  ', ' ')\n",
        "\n",
        "    # Padrões de normalização\n",
        "    padroes_normalizacao = [\n",
        "        # Padrões PGFN\n",
        "        (r'Parecer\\s+SEI\\s+(?:N[º°]\\s+)?([\\d\\.]+/\\d{4}/(?:CRJ/PGACET/)?PGFN(?:-MF|-ME)?)',\n",
        "         lambda m: f'Parecer SEI nº {m.group(1)}'),\n",
        "        (r'Nota\\s+SEI\\s+(?:N[º°]\\s+)?([\\d\\.]+/\\d{4}/(?:CRJ/PGACET/)?PGFN(?:-MF|-ME)?)',\n",
        "         lambda m: f'Nota SEI nº {m.group(1)}'),\n",
        "        (r'Parecer\\s+PGFN/(?:CAT|PGA|CRJ)/(?:N[º°]\\s+)?([\\d\\.]+(?:/\\d{4})?)',\n",
        "         lambda m: f'Parecer PGFN nº {m.group(1)}'),\n",
        "        (r'Nota\\s+PGFN\\s+(?:CRJ\\s+)?(?:N[º°]\\s+)?([\\d\\.]+/\\d{4})',\n",
        "         lambda m: f'Nota PGFN nº {m.group(1)}'),\n",
        "        (r'(?:Ato\\s+Declaratório\\s+)?PGFN(?:/CRJ)?(?:/N[º°]\\s+)?([\\d\\.]+(?:/\\d{4})?)',\n",
        "         lambda m: f'Ato Declaratório PGFN nº {m.group(1)}'),\n",
        "        (r'AD\\s+PGFN\\s+(?:N[º°]\\s+)?([\\d\\.]+)',\n",
        "         lambda m: f'Ato Declaratório PGFN nº {m.group(1)}'),\n",
        "        (r'Ato\\s+Declaratório\\s+PGFN\\s+(?:N[º°]\\s+)?([\\d\\.]+)',\n",
        "         lambda m: f'Ato Declaratório PGFN nº {m.group(1)}'),\n",
        "\n",
        "        # Instrução Normativa\n",
        "        (r'Instrução\\s+Normativa\\s+(?:RFB\\s+)?(?:SRF\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Instrução Normativa nº {m.group(1)}'),\n",
        "\n",
        "        # Lei\n",
        "        (r'Lei\\s+(?:Complementar\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Lei nº {m.group(1)}'),\n",
        "\n",
        "        # Decreto\n",
        "        (r'Decreto\\s+N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Decreto nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório RFB\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:RFB\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório SRF\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:SRF\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório SRF nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório CST\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:CST\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório CST nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório COSIT\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:Cosit\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório Cosit nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório COSAR\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:Cosar\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório Cosar nº {m.group(1)}'),\n",
        "\n",
        "        # Portaria\n",
        "        (r'Portaria\\s+(?:RFB\\s+)?(?:MF\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Portaria nº {m.group(1)}'),\n",
        "\n",
        "        # Resolução\n",
        "        (r'Resolução\\s+(?:RFB\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Resolução nº {m.group(1)}'),\n",
        "\n",
        "        # Medida Provisória\n",
        "        (r'Medida\\s+Provisória\\s+N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Medida Provisória nº {m.group(1)}'),\n",
        "\n",
        "        # Parecer Normativo\n",
        "        (r'Parecer\\s+Normativo\\s+(?:RFB\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Parecer Normativo nº {m.group(1)}'),\n",
        "\n",
        "        # Solução de Consulta\n",
        "        (r'Solução\\s+de\\s+Consulta\\s+(?:Cosit\\s+)?N[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Solução de Consulta nº {m.group(1)}'),\n",
        "\n",
        "        # RIR\n",
        "        (r'RIR/(\\d{4})',\n",
        "         lambda m: f'RIR/{m.group(1)}')\n",
        "    ]\n",
        "\n",
        "    # Aplicar cada padrão de normalização\n",
        "    norma_padronizada = norma\n",
        "    for padrao, substituicao in padroes_normalizacao:\n",
        "        match = re.search(padrao, norma, re.IGNORECASE)\n",
        "        if match:\n",
        "            norma_padronizada = substituicao(match)\n",
        "            break  # Sai após o primeiro padrão correspondido\n",
        "\n",
        "    return norma_padronizada\n",
        "\n",
        "def analisar_normas_excel(caminho_arquivo):\n",
        "    # Ler o arquivo Excel\n",
        "    print(\"Lendo arquivo Excel...\")\n",
        "    df = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "    # Criar lista de todas as normas\n",
        "    todas_normas = []\n",
        "    print(\"\\nProcessando e padronizando normas...\")\n",
        "\n",
        "    for normas_string in df['Norma']:\n",
        "        if isinstance(normas_string, str):\n",
        "            if normas_string.lower() == \"não tem norma legal para essa pergunta\":\n",
        "                continue\n",
        "\n",
        "            # Dividir múltiplas normas da mesma célula\n",
        "            normas_lista = re.split(r';|\\n', normas_string)\n",
        "\n",
        "            # Padronizar cada norma individualmente\n",
        "            for norma in normas_lista:\n",
        "                norma_padronizada = padronizar_norma(norma)\n",
        "                if norma_padronizada:  # Adicionar apenas se não estiver vazia\n",
        "                    todas_normas.append(norma_padronizada)\n",
        "\n",
        "    # Criar conjunto para remover duplicatas e depois converter para lista ordenada\n",
        "    normas_unicas = sorted(set(todas_normas))\n",
        "\n",
        "    # Criar DataFrame com normas únicas\n",
        "    df_normas_unicas = pd.DataFrame(normas_unicas, columns=['Norma'])\n",
        "\n",
        "    # Adicionar coluna com numeração\n",
        "    df_normas_unicas.insert(0, 'ID', range(1, len(df_normas_unicas) + 1))\n",
        "\n",
        "    # Imprimir estatísticas detalhadas\n",
        "    print(\"\\nEstatísticas:\")\n",
        "    print(f\"Total de normas encontradas (com repetições): {len(todas_normas)}\")\n",
        "    print(f\"Total de normas únicas após padronização: {len(normas_unicas)}\")\n",
        "\n",
        "    # Calcular e mostrar as normas mais frequentes\n",
        "    normas_freq = pd.Series(todas_normas).value_counts()\n",
        "    print(\"\\nTop 10 normas mais frequentes:\")\n",
        "    for norma, freq in normas_freq.head(10).items():\n",
        "        print(f\"{freq} ocorrências: {norma}\")\n",
        "\n",
        "    # Salvar normas únicas em um novo arquivo Excel\n",
        "    nome_arquivo_saida = 'normas_unicas_padronizadas.xlsx'\n",
        "    df_normas_unicas.to_excel(nome_arquivo_saida, index=False)\n",
        "\n",
        "    # Salvar arquivo com frequência das normas\n",
        "    nome_arquivo_freq = 'frequencia_normas_padronizadas.xlsx'\n",
        "    df_frequencia = pd.DataFrame({\n",
        "        'Norma': normas_freq.index,\n",
        "        'Frequência': normas_freq.values\n",
        "    })\n",
        "    df_frequencia.to_excel(nome_arquivo_freq, index=False)\n",
        "\n",
        "    # Mostrar as primeiras normas únicas encontradas\n",
        "    print(\"\\nPrimeiras 10 normas únicas encontradas:\")\n",
        "    print(df_normas_unicas.head(10))\n",
        "\n",
        "    return df_normas_unicas, df_frequencia\n",
        "\n",
        "# Usar a função\n",
        "try:\n",
        "    caminho_arquivo = 'normas_extraidas.xlsx'  # Arquivo gerado pelo código anterior\n",
        "    df_normas, df_freq = analisar_normas_excel(caminho_arquivo)\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao processar o arquivo: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8CKxF-1uMCA",
        "outputId": "8e8afc6f-c7ce-453e-9d1a-e694f2537280"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo arquivo Excel...\n",
            "\n",
            "Processando e padronizando normas...\n",
            "\n",
            "Estatísticas:\n",
            "Total de normas encontradas (com repetições): 1839\n",
            "Total de normas únicas após padronização: 336\n",
            "\n",
            "Top 10 normas mais frequentes:\n",
            "260 ocorrências: RIR/2018\n",
            "260 ocorrências: Decreto nº 9.580\n",
            "123 ocorrências: Instrução Normativa nº 1.500\n",
            "79 ocorrências: Lei nº 7.713\n",
            "77 ocorrências: Lei nº 9.250\n",
            "67 ocorrências: Instrução Normativa nº 83\n",
            "56 ocorrências: Instrução Normativa nº 208\n",
            "48 ocorrências: Instrução Normativa nº 2.178\n",
            "47 ocorrências: Instrução Normativa nº 84\n",
            "39 ocorrências: Instrução Normativa nº 1.585\n",
            "\n",
            "Primeiras 10 normas únicas encontradas:\n",
            "   ID                         Norma\n",
            "0   1  Ato Declaratório Cosar nº 47\n",
            "1   2    Ato Declaratório PGFN nº .\n",
            "2   3    Ato Declaratório PGFN nº 1\n",
            "3   4   Ato Declaratório PGFN nº 13\n",
            "4   5   Ato Declaratório PGFN nº 14\n",
            "5   6    Ato Declaratório PGFN nº 2\n",
            "6   7    Ato Declaratório PGFN nº 3\n",
            "7   8    Ato Declaratório PGFN nº 4\n",
            "8   9    Ato Declaratório PGFN nº 5\n",
            "9  10    Ato Declaratório PGFN nº 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''#@title Padronização\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def padronizar_norma(norma):\n",
        "    \"\"\"Função para padronizar o formato da norma removendo datas e outros elementos variáveis\"\"\"\n",
        "    if not isinstance(norma, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Limpar espaços e quebras de linha\n",
        "    norma = norma.strip().replace('\\n', ' ').replace('  ', ' ')\n",
        "\n",
        "    # Verificar primeiro se é o Decreto 9.580 e converter para RIR/2018\n",
        "    if re.search(r'Decreto\\s*n[º°]\\s*9\\.580(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?', norma, re.IGNORECASE):\n",
        "        return 'RIR/2018'\n",
        "\n",
        "    # Padrões de normalização\n",
        "    padroes_normalizacao = [\n",
        "        # Lei (com ou sem data)\n",
        "        (r'Lei\\s+(?:Complementar\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Lei nº {m.group(1)}'),\n",
        "\n",
        "        # Instrução Normativa\n",
        "        (r'Instrução\\s+Normativa\\s+(?:RFB\\s+)?(?:SRF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Instrução Normativa RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Decreto\n",
        "        (r'Decreto\\s*n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Decreto nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório RFB\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Ato Declaratório RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório SRF\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:SRF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Ato Declaratório SRF nº {m.group(1)}'),\n",
        "\n",
        "        # Portaria\n",
        "        (r'Portaria\\s+(?:RFB\\s+)?(?:MF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Portaria RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Resolução\n",
        "        (r'Resolução\\s+(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Resolução RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Medida Provisória\n",
        "        (r'Medida\\s+Provisória\\s+n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Medida Provisória nº {m.group(1)}'),\n",
        "\n",
        "        # Parecer Normativo\n",
        "        (r'Parecer\\s+Normativo\\s+(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Parecer Normativo RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Solução de Consulta\n",
        "        (r'Solução\\s+de\\s+Consulta\\s+(?:Cosit\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de\\s*[\\d\\.]+\\s+de\\s+\\w+\\s+de\\s+\\d{4})?',\n",
        "         lambda m: f'Solução de Consulta Cosit nº {m.group(1)}'),\n",
        "\n",
        "        # RIR\n",
        "        (r'RIR/(\\d{4})',\n",
        "         lambda m: f'RIR/{m.group(1)}')\n",
        "    ]\n",
        "\n",
        "    # Aplicar cada padrão de normalização\n",
        "    norma_padronizada = norma\n",
        "    for padrao, substituicao in padroes_normalizacao:\n",
        "        match = re.search(padrao, norma, re.IGNORECASE)\n",
        "        if match:\n",
        "            norma_padronizada = substituicao(match)\n",
        "            break\n",
        "\n",
        "    return norma_padronizada\n",
        "\n",
        "def analisar_normas_excel(caminho_arquivo):\n",
        "    # Ler o arquivo Excel\n",
        "    print(\"Lendo arquivo Excel...\")\n",
        "    df = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "    # Criar lista de todas as normas\n",
        "    todas_normas = []\n",
        "    print(\"\\nProcessando e padronizando normas...\")\n",
        "\n",
        "    for normas_string in df['Norma']:\n",
        "        if isinstance(normas_string, str):\n",
        "            if normas_string == \"não tem norma legal para essa pergunta\":\n",
        "                continue\n",
        "\n",
        "            # Dividir múltiplas normas da mesma célula\n",
        "            normas_lista = normas_string.split(';')\n",
        "\n",
        "            # Padronizar cada norma individualmente\n",
        "            for norma in normas_lista:\n",
        "                norma_padronizada = padronizar_norma(norma)\n",
        "                if norma_padronizada:  # Adicionar apenas se não estiver vazia\n",
        "                    todas_normas.append(norma_padronizada)\n",
        "\n",
        "    # Criar conjunto para remover duplicatas e depois converter para lista ordenada\n",
        "    normas_unicas = sorted(set(todas_normas))\n",
        "\n",
        "    # Criar DataFrame com normas únicas\n",
        "    df_normas_unicas = pd.DataFrame(normas_unicas, columns=['Norma'])\n",
        "\n",
        "    # Adicionar coluna com numeração\n",
        "    df_normas_unicas.insert(0, 'ID', range(1, len(df_normas_unicas) + 1))\n",
        "\n",
        "    # Imprimir estatísticas detalhadas\n",
        "    print(\"\\nEstatísticas:\")\n",
        "    print(f\"Total de normas encontradas (com repetições): {len(todas_normas)}\")\n",
        "    print(f\"Total de normas únicas após padronização: {len(normas_unicas)}\")\n",
        "\n",
        "    # Calcular e mostrar as normas mais frequentes\n",
        "    normas_freq = pd.Series(todas_normas).value_counts()\n",
        "    print(\"\\nTop 10 normas mais frequentes:\")\n",
        "    for norma, freq in normas_freq.head(10).items():\n",
        "        print(f\"{freq} ocorrências: {norma}\")\n",
        "\n",
        "    # Salvar normas únicas em um novo arquivo Excel\n",
        "    nome_arquivo_saida = 'normas_unicas_padronizadas.xlsx'\n",
        "    df_normas_unicas.to_excel(nome_arquivo_saida, index=False)\n",
        "\n",
        "    # Salvar arquivo com frequência das normas\n",
        "    nome_arquivo_freq = 'frequencia_normas_padronizadas.xlsx'\n",
        "    df_frequencia = pd.DataFrame({\n",
        "        'Norma': normas_freq.index,\n",
        "        'Frequência': normas_freq.values\n",
        "    })\n",
        "    df_frequencia.to_excel(nome_arquivo_freq, index=False)\n",
        "\n",
        "    # Se estiver no Google Colab, fazer o download dos arquivos\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(nome_arquivo_saida)\n",
        "        files.download(nome_arquivo_freq)\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados e estão disponíveis para download.\")\n",
        "    except:\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados no diretório atual.\")\n",
        "\n",
        "    # Mostrar as primeiras normas únicas encontradas\n",
        "    print(\"\\nPrimeiras 10 normas únicas encontradas:\")\n",
        "    print(df_normas_unicas.head(10))\n",
        "\n",
        "    return df_normas_unicas, df_frequencia\n",
        "\n",
        "# Usar a função\n",
        "try:\n",
        "    caminho_arquivo = 'normas_extraidas.xlsx'  # Arquivo gerado pelo código anterior\n",
        "    df_normas, df_freq = analisar_normas_excel(caminho_arquivo)\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao processar o arquivo: {str(e)}\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "q03QLi5jIQTd",
        "outputId": "bdbb050f-00cb-47c2-c68c-2592b4669513"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo arquivo Excel...\n",
            "\n",
            "Processando e padronizando normas...\n",
            "\n",
            "Estatísticas:\n",
            "Total de normas encontradas (com repetições): 1790\n",
            "Total de normas únicas após padronização: 300\n",
            "\n",
            "Top 10 normas mais frequentes:\n",
            "520 ocorrências: RIR/2018\n",
            "123 ocorrências: Instrução Normativa RFB nº 1.500\n",
            "79 ocorrências: Lei nº 7.713\n",
            "77 ocorrências: Lei nº 9.250\n",
            "67 ocorrências: Instrução Normativa RFB nº 83\n",
            "56 ocorrências: Instrução Normativa RFB nº 208\n",
            "48 ocorrências: Instrução Normativa RFB nº 2.178\n",
            "47 ocorrências: Instrução Normativa RFB nº 84\n",
            "39 ocorrências: Instrução Normativa RFB nº 1.585\n",
            "24 ocorrências: Lei nº 10.406\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33380ca6-5a21-40ea-baf2-26cf8ff036de\", \"normas_unicas_padronizadas.xlsx\", 9942)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0bbcd9dd-64df-4837-9a65-d9781e950626\", \"frequencia_normas_padronizadas.xlsx\", 9241)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Arquivos 'normas_unicas_padronizadas.xlsx' e 'frequencia_normas_padronizadas.xlsx' foram gerados e estão disponíveis para download.\n",
            "\n",
            "Primeiras 10 normas únicas encontradas:\n",
            "   ID                       Norma\n",
            "0   1   Ato Declaratório RFB nº 1\n",
            "1   2  Ato Declaratório RFB nº 16\n",
            "2   3  Ato Declaratório RFB nº 18\n",
            "3   4   Ato Declaratório RFB nº 3\n",
            "4   5           Decreto nº 21.177\n",
            "5   6           Decreto nº 27.784\n",
            "6   7            Decreto nº 3.000\n",
            "7   8              Decreto nº 361\n",
            "8   9            Decreto nº 4.897\n",
            "9  10            Decreto nº 5.128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Padronização\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def padronizar_norma(norma):\n",
        "    \"\"\"Função para padronizar o formato da norma removendo datas e outros elementos variáveis\"\"\"\n",
        "    if not isinstance(norma, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Limpar espaços e quebras de linha\n",
        "    norma = norma.strip().replace('\\n', ' ').replace('  ', ' ')\n",
        "\n",
        "    # Verificar primeiro se é o Decreto nº 9.580 e converter para RIR/2018\n",
        "    if re.search(r'Decreto\\s*n[º°]\\s*9\\.580(?:\\s*,\\s*de.*)?', norma, re.IGNORECASE):\n",
        "        return 'RIR/2018'\n",
        "\n",
        "    # Padrões de normalização\n",
        "    padroes_normalizacao = [\n",
        "        # Padrões PGFN\n",
        "        (r'Parecer\\s+SEI\\s+(?:N[º°]\\s+)?([\\d\\.]+/\\d{4}/(?:CRJ/PGACET/)?PGFN(?:-MF|-ME)?)',\n",
        "         lambda m: f'Parecer SEI nº {m.group(1)}'),\n",
        "        (r'Nota\\s+SEI\\s+(?:N[º°]\\s+)?([\\d\\.]+/\\d{4}/(?:CRJ/PGACET/)?PGFN(?:-MF|-ME)?)',\n",
        "         lambda m: f'Nota SEI nº {m.group(1)}'),\n",
        "        (r'Parecer\\s+PGFN/(?:CAT|PGA|CRJ)/(?:N[º°]\\s+)?([\\d\\.]+(?:/\\d{4})?)',\n",
        "         lambda m: f'Parecer PGFN nº {m.group(1)}'),\n",
        "        (r'Nota\\s+PGFN\\s+(?:CRJ\\s+)?(?:N[º°]\\s+)?([\\d\\.]+/\\d{4})',\n",
        "         lambda m: f'Nota PGFN nº {m.group(1)}'),\n",
        "        (r'(?:Ato\\s+Declaratório\\s+)?PGFN(?:/CRJ)?(?:/N[º°]\\s+)?([\\d\\.]+(?:/\\d{4})?)',\n",
        "         lambda m: f'Ato Declaratório PGFN nº {m.group(1)}'),\n",
        "        (r'AD\\s+PGFN\\s+(?:N[º°]\\s+)?([\\d\\.]+)',\n",
        "         lambda m: f'Ato Declaratório PGFN nº {m.group(1)}'),\n",
        "        (r'Ato\\s+Declaratório\\s+PGFN\\s+(?:N[º°]\\s+)?([\\d\\.]+)',\n",
        "         lambda m: f'Ato Declaratório PGFN nº {m.group(1)}'),\n",
        "\n",
        "        # Lei (com ou sem data)\n",
        "        (r'Lei\\s+(?:Complementar\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Lei nº {m.group(1)}'),\n",
        "\n",
        "        # Instrução Normativa\n",
        "        (r'Instrução\\s+Normativa\\s+(?:RFB\\s+)?(?:SRF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Instrução Normativa RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Decreto (geral)\n",
        "        (r'Decreto\\s*n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Decreto nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório RFB\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório SRF\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:SRF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório SRF nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório CST\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:CST\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório CST nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório Cosit\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:Cosit\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório Cosit nº {m.group(1)}'),\n",
        "\n",
        "        # Ato Declaratório Cosar\n",
        "        (r'Ato\\s+Declaratório\\s+(?:Interpretativo\\s+)?(?:Cosar\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Ato Declaratório Cosar nº {m.group(1)}'),\n",
        "\n",
        "        # Portaria\n",
        "        (r'Portaria\\s+(?:RFB\\s+)?(?:MF\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Portaria nº {m.group(1)}'),\n",
        "\n",
        "        # Resolução\n",
        "        (r'Resolução\\s+(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Resolução nº {m.group(1)}'),\n",
        "\n",
        "        # Medida Provisória\n",
        "        (r'Medida\\s+Provisória\\s+n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Medida Provisória nº {m.group(1)}'),\n",
        "\n",
        "        # Parecer Normativo\n",
        "        (r'Parecer\\s+Normativo\\s+(?:RFB\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Parecer Normativo RFB nº {m.group(1)}'),\n",
        "\n",
        "        # Solução de Consulta\n",
        "        (r'Solução\\s+de\\s+Consulta\\s+(?:Cosit\\s+)?n[º°]\\s*([\\d\\.]+)(?:\\s*,\\s*de.*)?',\n",
        "         lambda m: f'Solução de Consulta Cosit nº {m.group(1)}'),\n",
        "\n",
        "        # RIR\n",
        "        (r'RIR/(\\d{4})',\n",
        "         lambda m: f'RIR/{m.group(1)}')\n",
        "    ]\n",
        "\n",
        "    # Aplicar cada padrão de normalização\n",
        "    norma_padronizada = norma\n",
        "    for padrao, substituicao in padroes_normalizacao:\n",
        "        match = re.search(padrao, norma, re.IGNORECASE)\n",
        "        if match:\n",
        "            norma_padronizada = substituicao(match)\n",
        "            break\n",
        "\n",
        "    return norma_padronizada\n",
        "\n",
        "def analisar_normas_excel(caminho_arquivo):\n",
        "    # Ler o arquivo Excel\n",
        "    print(\"Lendo arquivo Excel...\")\n",
        "    df = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "    # Criar lista de todas as normas\n",
        "    todas_normas = []\n",
        "    print(\"\\nProcessando e padronizando normas...\")\n",
        "\n",
        "    for normas_string in df['Norma']:\n",
        "        if isinstance(normas_string, str):\n",
        "            if normas_string.lower() == \"não tem norma legal para essa pergunta\":\n",
        "                continue\n",
        "\n",
        "            # Dividir múltiplas normas da mesma célula\n",
        "            normas_lista = re.split(r';|\\n', normas_string)\n",
        "\n",
        "            # Padronizar cada norma individualmente\n",
        "            for norma in normas_lista:\n",
        "                norma_padronizada = padronizar_norma(norma)\n",
        "                if norma_padronizada:  # Adicionar apenas se não estiver vazia\n",
        "                    todas_normas.append(norma_padronizada)\n",
        "\n",
        "    # Criar conjunto para remover duplicatas e depois converter para lista ordenada\n",
        "    normas_unicas = sorted(set(todas_normas))\n",
        "\n",
        "    # Criar DataFrame com normas únicas\n",
        "    df_normas_unicas = pd.DataFrame(normas_unicas, columns=['Norma'])\n",
        "\n",
        "    # Adicionar coluna com numeração\n",
        "    df_normas_unicas.insert(0, 'ID', range(1, len(df_normas_unicas) + 1))\n",
        "\n",
        "    # Imprimir estatísticas detalhadas\n",
        "    print(\"\\nEstatísticas:\")\n",
        "    print(f\"Total de normas encontradas (com repetições): {len(todas_normas)}\")\n",
        "    print(f\"Total de normas únicas após padronização: {len(normas_unicas)}\")\n",
        "\n",
        "    # Calcular e mostrar as normas mais frequentes\n",
        "    normas_freq = pd.Series(todas_normas).value_counts()\n",
        "    print(\"\\nTop 10 normas mais frequentes:\")\n",
        "    for norma, freq in normas_freq.head(10).items():\n",
        "        print(f\"{freq} ocorrências: {norma}\")\n",
        "\n",
        "    # Salvar normas únicas em um novo arquivo Excel\n",
        "    nome_arquivo_saida = 'normas_unicas_padronizadas.xlsx'\n",
        "    df_normas_unicas.to_excel(nome_arquivo_saida, index=False)\n",
        "\n",
        "    # Salvar arquivo com frequência das normas\n",
        "    nome_arquivo_freq = 'frequencia_normas_padronizadas.xlsx'\n",
        "    df_frequencia = pd.DataFrame({\n",
        "        'Norma': normas_freq.index,\n",
        "        'Frequência': normas_freq.values\n",
        "    })\n",
        "    df_frequencia.to_excel(nome_arquivo_freq, index=False)\n",
        "\n",
        "    # Se estiver no Google Colab, fazer o download dos arquivos\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(nome_arquivo_saida)\n",
        "        files.download(nome_arquivo_freq)\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados e estão disponíveis para download.\")\n",
        "    except:\n",
        "        print(f\"\\nArquivos '{nome_arquivo_saida}' e '{nome_arquivo_freq}' foram gerados no diretório atual.\")\n",
        "\n",
        "    # Mostrar as primeiras normas únicas encontradas\n",
        "    print(\"\\nPrimeiras 10 normas únicas encontradas:\")\n",
        "    print(df_normas_unicas.head(10))\n",
        "\n",
        "    return df_normas_unicas, df_frequencia\n",
        "\n",
        "# Usar a função\n",
        "try:\n",
        "    caminho_arquivo = 'normas_extraidas.xlsx'  # Arquivo gerado pelo código anterior\n",
        "    df_normas, df_freq = analisar_normas_excel(caminho_arquivo)\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao processar o arquivo: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "XA3G-jWSvFez",
        "outputId": "1bc6f799-a249-4da4-d5db-059235646b1a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo arquivo Excel...\n",
            "\n",
            "Processando e padronizando normas...\n",
            "\n",
            "Estatísticas:\n",
            "Total de normas encontradas (com repetições): 1839\n",
            "Total de normas únicas após padronização: 335\n",
            "\n",
            "Top 10 normas mais frequentes:\n",
            "520 ocorrências: RIR/2018\n",
            "123 ocorrências: Instrução Normativa RFB nº 1.500\n",
            "79 ocorrências: Lei nº 7.713\n",
            "77 ocorrências: Lei nº 9.250\n",
            "67 ocorrências: Instrução Normativa RFB nº 83\n",
            "56 ocorrências: Instrução Normativa RFB nº 208\n",
            "48 ocorrências: Instrução Normativa RFB nº 2.178\n",
            "47 ocorrências: Instrução Normativa RFB nº 84\n",
            "39 ocorrências: Instrução Normativa RFB nº 1.585\n",
            "24 ocorrências: Lei nº 10.406\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4c275f6f-eca5-4a10-a720-74625d76022d\", \"normas_unicas_padronizadas.xlsx\", 10599)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29b4154d-b226-42f5-823d-c7b85108cc90\", \"frequencia_normas_padronizadas.xlsx\", 9864)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Arquivos 'normas_unicas_padronizadas.xlsx' e 'frequencia_normas_padronizadas.xlsx' foram gerados e estão disponíveis para download.\n",
            "\n",
            "Primeiras 10 normas únicas encontradas:\n",
            "   ID                         Norma\n",
            "0   1  Ato Declaratório Cosar nº 47\n",
            "1   2    Ato Declaratório PGFN nº .\n",
            "2   3    Ato Declaratório PGFN nº 1\n",
            "3   4   Ato Declaratório PGFN nº 13\n",
            "4   5   Ato Declaratório PGFN nº 14\n",
            "5   6    Ato Declaratório PGFN nº 2\n",
            "6   7    Ato Declaratório PGFN nº 3\n",
            "7   8    Ato Declaratório PGFN nº 4\n",
            "8   9    Ato Declaratório PGFN nº 5\n",
            "9  10    Ato Declaratório PGFN nº 6\n"
          ]
        }
      ]
    }
  ]
}